import pickle
from typing import Any

import pydantic

from tensorlake.function_executor.proto.function_executor_pb2 import (
    SerializedObjectEncoding,
)

from .interface.exceptions import (
    DeserializationError,
    InternalError,
    SerializationError,
)

# Application function calls use JSON serializer because application function
# cacall can be done over HTTP using any HTTP client. So we need a universal
# serialization format that can be used by any HTTP client in any programming language.
# JSON is a widely supported serialization format so we use it for application function calls.
APPLICATION_FUNCTION_CALL_SERIALIZER_NAME: str = "json"
# All non-application (aka internal/SDK) function calls are initiated using Python SDK where Pickle
# is available. Pickle can serialize most Python objects and it's compatible between
# different Python versions. This allows users to not care about serialization
# format used between non-application (internal/SDK) function calls. This is why we use it
# for all non-application (internal/SDK) functions.
SDK_FUNCTION_CALL_SERIALIZER_NAME: str = "pickle"


class UserDataSerializer:
    """A serializer used to serialize and deserialize user data.

    The serializer must only be used for user data because it implements
    heuristics specific to user data.
    """

    @property
    def name(self) -> str:
        """Returns the name of the serializer."""
        raise InternalError("Subclasses should implement this method.")

    @property
    def content_type(self) -> str:
        """Returns the content type of the serializer."""
        raise InternalError("Subclasses should implement this method.")

    @property
    def serialized_object_encoding(self) -> SerializedObjectEncoding:
        """Returns the serialized object encoding of the serializer."""
        raise InternalError("Subclasses should implement this method.")

    def serialize(self, object: Any, type_hint: Any) -> bytes:
        """Serializes the given object into bytes.

        The type_hint parameter specifies the possible type or type hint of the serialized object.
        type(object) is not the same as type_hint, i.e.
        type(object) is list, type_hint is List[int].

        Raises SerializationError on failure.
        """
        raise InternalError("Subclasses should implement this method.")

    def deserialize(self, data: bytearray | bytes | memoryview, type_hint: Any) -> Any:
        """Deserializes the given bytes into an object.

        The `type_hint` parameter specifies the expected type or type hint of the deserialized object.
        type(object) is not the same as type_hint, i.e.
        type(object) is list, type_hint is List[int].

        Raises DeserializationError on failure.
        """
        raise InternalError("Subclasses should implement this method.")


def create_type_adapter(type_hint: Any) -> pydantic.TypeAdapter:
    """Creates a Pydantic TypeAdapter for the given type hint.

    Raises an Exception generated by Pydantic as is if the type hint
    is not supported by Pydantic.
    """
    return pydantic.TypeAdapter(type_hint)


def generate_json_schema(type_adapter: pydantic.TypeAdapter) -> dict[str, Any]:
    """Generates a JSON schema for the given Pydantic TypeAdapter.

    Raises an Exception generated by Pydantic as is if the type adapter
    doesn't support JSON schema generation.
    """
    return type_adapter.json_schema()


class JSONUserDataSerializer(UserDataSerializer):
    """A serializer that does text serialization into JSON format.

    It serializes Pydantic models and built-in Python types supported by Pydantic.
    The models and built-in types must be JSON serializable by Pydantic.
    This approach supports much much more use cases than standard json module.
    i.e. it support model fields inside built-in types like dict[str, ModelClass],
    it converts json lists into sets if deserializing into set[...],
    it converts json string object keys into int keys if deserializing into dict[int, ...], etc.
    See more at https://docs.pydantic.dev/latest/concepts/serialization/#json-mode.
    """

    NAME = "json"
    CONTENT_TYPE = "application/json; charset=UTF-8"

    @property
    def name(self) -> str:
        return self.NAME

    @property
    def content_type(self) -> str:
        return self.CONTENT_TYPE

    @property
    def serialized_object_encoding(self) -> SerializedObjectEncoding:
        return SerializedObjectEncoding.SERIALIZED_OBJECT_ENCODING_UTF8_JSON

    def serialize(self, object: Any, type_hint: Any) -> bytes:
        try:
            adapter: pydantic.TypeAdapter = create_type_adapter(type_hint)
            # i.e. converts a dict into a Pydantic model instance if type_hint includes
            # a Pydantic model that matches the dict.
            validated_obj: Any = adapter.validate_python(object)
            return adapter.dump_json(validated_obj, warnings="error")
        except Exception as e:
            raise SerializationError(
                f"Failed to serialize '{object}' as '{type_hint}' to json: {e}"
            ) from e

    def deserialize(self, data: bytearray | bytes | memoryview, type_hint: Any) -> Any:
        if isinstance(data, memoryview):
            # Pydantic only supports bytes or bytearray.
            data: bytes | bytearray = data.tobytes()

        try:
            return create_type_adapter(type_hint).validate_json(data)
        except Exception as e:
            raise DeserializationError(
                f"Failed to deserialize data '{data}' as '{type_hint}' with json serializer: {e}"
            ) from e


class PickleUserDataSerializer(UserDataSerializer):
    """A serializer that uses binary serialization with pickle.

    The pickle format is not human-readable and can only be used in Python.
    It's compatible between Python versions (3.8+ in our case).
    Users are responsible for compatibility of data they are serializing, i.e.
    a Pandas DataFrame serialized on newer Pandas versions might not be readable
    on older versions.
    """

    NAME = "pickle"
    CONTENT_TYPE = "application/python-pickle"
    _PROTOCOL_LEVEL = 5  # Python 3.8+ only, most efficient.

    @property
    def name(self) -> str:
        return self.NAME

    @property
    def content_type(self) -> str:
        return self.CONTENT_TYPE

    @property
    def serialized_object_encoding(self) -> SerializedObjectEncoding:
        return SerializedObjectEncoding.SERIALIZED_OBJECT_ENCODING_BINARY_PICKLE

    def serialize(self, object: Any, type_hint: Any) -> bytes:
        try:
            return pickle.dumps(object, protocol=self._PROTOCOL_LEVEL)
        except Exception as e:
            raise SerializationError(
                f"Failed to serialize data with pickle serializer: {e}"
            ) from e

    def deserialize(self, data: bytearray | bytes | memoryview, type_hint: Any) -> Any:
        try:
            return pickle.loads(data)
        except Exception as e:
            raise DeserializationError(
                f"Failed to deserialize data with pickle serializer: {e}"
            ) from e


def serializer_by_name(serializer_name: str) -> UserDataSerializer:
    """Returns the UserDataSerializer instance for the given serializer name.

    The caller must validate the serializer name beforehand.
    Raises InternalError if the serializer name is unknown.
    """
    if serializer_name == PickleUserDataSerializer.NAME:
        return PickleUserDataSerializer()
    elif serializer_name == JSONUserDataSerializer.NAME:
        return JSONUserDataSerializer()
    # We're validating application serializers on app deployment so this should never happen.
    raise InternalError(f"Unknown serializer name: {serializer_name}")
